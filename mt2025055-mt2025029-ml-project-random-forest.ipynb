{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13487237,"sourceType":"datasetVersion","datasetId":8563004}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport optuna\nfrom sklearn.model_selection import StratifiedKFold, train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.ensemble import RandomForestClassifier\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/ob-data/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/ob-data/test.csv\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Train shape:\", train.shape)\nprint(\"Test shape:\", test.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"\\n--- Basic Information ---\")\nprint(train.info())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"\\n--- Summary Statistics (Numerical Columns) ---\")\nprint(train.describe().T)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Feature-Target Correlation\ntarget_map = {cat:i for i, cat in enumerate(train[\"WeightCategory\"].unique())}\ntrain[\"TargetNum\"] = train[\"WeightCategory\"].map(target_map)\n\nprint(\"\\n--- Feature Correlation with Target ---\")\nprint(train[num_cols + [\"TargetNum\"]].corr()[\"TargetNum\"].sort_values(ascending=False))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X = train.drop(columns=[\"WeightCategory\", \"id\"])\ny = train[\"WeightCategory\"]\n\nprint(\"Features shape:\", X.shape, \"Target shape:\", y.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cat_cols = X.select_dtypes(include=[\"object\"]).columns.tolist()\nX_encoded = pd.get_dummies(X, columns=cat_cols, drop_first=False)\ntest_encoded = pd.get_dummies(test.drop(columns=[\"id\"], errors=\"ignore\"), columns=cat_cols, drop_first=False)\n\ntest_encoded = test_encoded.reindex(columns=X_encoded.columns, fill_value=0)\n\nle = LabelEncoder()\ny_encoded = le.fit_transform(y)\n\nX_np = X_encoded.values\ny_np = y_encoded\ntest_np = test_encoded.values\n\nprint(\"Train shape:\", X_encoded.shape, \"Test shape:\", test_encoded.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def objective(trial):\n    params = {\n        \"n_estimators\": trial.suggest_int(\"n_estimators\", 200, 800),\n        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 20),\n        \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 10),\n        \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 5),\n        \"max_features\": trial.suggest_categorical(\"max_features\", [\"sqrt\", \"log2\", None])\n    }\n\n    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n    scores = []\n\n    for tr_idx, va_idx in cv.split(X_np, y_np):\n        X_tr, X_va = X_np[tr_idx], X_np[va_idx]\n        y_tr, y_va = y_np[tr_idx], y_np[va_idx]\n\n        model = RandomForestClassifier(**params, n_jobs=-1, random_state=42)\n        model.fit(X_tr, y_tr)\n        preds = model.predict(X_va)\n        scores.append(accuracy_score(y_va, preds))\n\n    return float(np.mean(scores))\n\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"study = optuna.create_study(direction=\"maximize\")\nstudy.optimize(objective, n_trials=80, show_progress_bar=True)  # can increase trials\n\nprint(\"Best CV score:\", round(study.best_value * 100, 2), \"%\")\nprint(\"Best params:\", study.best_params)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"K = 5\ntop_trials = sorted([t for t in study.trials if t.value is not None], key=lambda t: t.value, reverse=True)[:K]\n\nprint(f\"\\nTop {K} Optuna Trials to be used in ensemble:\")\nfor i, t in enumerate(top_trials, 1):\n    print(f\"\\nModel {i}:\")\n    print(f\"  CV Score: {t.value:.6f}\")\n    print(f\"  Parameters:\")\n    for param_name, param_value in t.params.items():\n        print(f\"    {param_name}: {param_value}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"K = 5\nX_tr_full, X_hold, y_tr_full, y_hold = train_test_split(X_np, y_np, test_size=0.15, random_state=99, stratify=y_np)\n\nmodels = []\nfor i, t in enumerate(top_trials):\n    params = t.params.copy()\n    m = RandomForestClassifier(**params, n_jobs=-1, random_state=42+i)\n    m.fit(X_tr_full, y_tr_full)\n    models.append(m)\n    print(f\" Trained ensemble member {i+1} (trial value={t.value:.4f})\")\n\n# Evaluate ensemble on holdout\nprobs = np.mean([m.predict_proba(X_hold) for m in models], axis=0)\nensemble_preds = np.argmax(probs, axis=1)\nensemble_acc = accuracy_score(y_hold, ensemble_preds)\nprint(f\"Ensemble holdout accuracy: {ensemble_acc*100:.4f}%\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Retraining ensemble members on full training data and predicting test...\")\n\nfinal_models = []\nfor i, t in enumerate(top_trials):\n    params = t.params.copy()\n    m = RandomForestClassifier(**params, n_jobs=-1, random_state=42+i)\n    m.fit(X_np, y_np)\n    final_models.append(m)\n    print(f\" Final model {i+1} trained.\")\n\ntest_probas = np.mean([m.predict_proba(test_np) for m in final_models], axis=0)\ntest_preds = np.argmax(test_probas, axis=1)\ntest_labels = le.inverse_transform(test_preds)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nsubmission = pd.DataFrame({\"id\": test[\"id\"], \"WeightCategory\": test_labels})\nsubmission.to_csv(\"Submission_randomForest.csv\", index=False)\nprint(\"Saved submission_optuna_ensemble.csv. Ensemble test distribution:\")\nprint(submission[\"WeightCategory\"].value_counts(normalize=True).round(3) * 100)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}